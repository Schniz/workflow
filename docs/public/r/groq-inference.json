{
  "name": "groq-inference",
  "type": "registry:block",
  "title": "Groq LPU Inference",
  "description": "Ultra-fast AI inference with Groq LPU technology",
  "registryDependencies": [],
  "dependencies": ["@vercel/workflow"],
  "files": [
    {
      "path": "registry/steps/groq-inference.tsx",
      "type": "registry:component",
      "content": "'use workflow';\n\nimport { workflow, fatalError } from '@vercel/workflow';\n\ntype GroqParams = {\n  messages: { role: string; content: string }[];\n  model?: string;\n};\n\nexport const groqInference = workflow(\n  'groq-inference',\n  async (params: GroqParams) => {\n    const apiKey = process.env.GROQ_API_KEY;\n\n    if (!apiKey) {\n      throw fatalError('GROQ_API_KEY is required');\n    }\n\n    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {\n      method: 'POST',\n      headers: {\n        'Authorization': \\`Bearer \\${apiKey}\\",
      "target": "components/steps/groq-inference.tsx"
    }
  ]
}
